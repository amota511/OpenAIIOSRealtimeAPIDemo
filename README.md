I noticed that most demos of OpenAI’s real-time API are either Node.js or web-based, so I decided to release the first iOS demo using Swift. Hope you enjoy it!



For IOS app, we need to carefully deal with the following items:
1) the audio collecting and processing
2) the interaction with Openai API
3) Ensuring the AI agent’s audio isn’t captured while it’s speaking

Watch till the end for valuable insights and unique implementation techniques!

LinkedIn:  https://www.linkedin.com/in/navbot-frank/

Youtube: https://www.youtube.com/watch?v=eWsvwTnscBA

See my previous demo:
Real-time API on Python: https://www.youtube.com/watch?v=lOypO-ngBJ8&t=3s

Real-time API live demo at OpenAI'dev day: https://www.youtube.com/watch?v=mVR90WmA34U&t=657s
